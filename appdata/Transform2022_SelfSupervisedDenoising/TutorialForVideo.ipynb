{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5960fec8",
   "metadata": {},
   "source": [
    "# SELF-SUPERVISED DENOISING: PART TWO\n",
    "### Authors: Claire Birnie and Sixiu Liu, KAUST\n",
    "\n",
    "Author websites: \n",
    "- https://cebirnie92.github.io/ \n",
    "- https://swagroup.kaust.edu.sa/people/detail/sixiu-liu-(%E5%88%98%E6%80%9D%E7%A7%80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdf19b",
   "metadata": {},
   "source": [
    "## Tutorial Overview\n",
    "\n",
    "On completion of this tutorial you will have learnt how to adapt your previously wrote blind-spot denoising procedure to handle noise that has some temporal relationship. In this instance, we imitate this using bandpassed noise. At the end of the tutorial, you will have the opportunity to denoise a field dataset often used for benchmarking random noise suppression procedures.\n",
    "\n",
    "### Recap\n",
    "As a reminder, the networks are trained in a self-supervised manner, i.e., the training data is the same as the inference data with no labels required! This tutorial is the second in the second in our self-supervised denoising series. For a recap on the methodology and the denoising performance under idealistic scenarios, review Tutorial One."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904afec8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe651d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "# Our unet functions just to speed things up\n",
    "from unet import UNet\n",
    "from tutorial_utils import regular_patching_2D, add_bandlimited_noise, weights_init, set_seed, make_data_loader,plot_corruption, plot_training_metrics, plot_synth_results, plot_field_results, multi_active_pixels, n2v_train, n2v_evaluate, fspectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d875ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='RdBu'\n",
    "vmin = -0.25\n",
    "vmax = 0.25\n",
    "\n",
    "set_seed(42) # For reproducibility set random, numpy and torch seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965b28e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af110b58",
   "metadata": {},
   "source": [
    "# Step One - Data loading\n",
    "\n",
    "In this example we are going to use a post-stack seismic section generated from the Hess VTI model. The post-stack section is available in the public data folder: https://exrcsdrive.kaust.edu.sa/exrcsdrive/index.php/s/vjjry6BZ3n3Ewei\n",
    "\n",
    "with password: `kaust`\n",
    "\n",
    "If the folder is no longer public, this is likely due to expired rights. Please email: cebirnie[at]kaust.edu.sa to request access.\n",
    "\n",
    "This is the first dataset as was used in tutorial One therefore we can load it quickly without too much investigation as we already know its size and what it looks like (hence, why no 'TO DOs' this time!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f35f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"/Users/ruslan/Documents/GitHub/Transform2022_SelfSupervisedDenoising/Data/Hess_PostStackSection.npy\")\n",
    "\n",
    "# Double-check the data dimensions\n",
    "print(d.shape)\n",
    "\n",
    "# Plot to see the noise free data\n",
    "plt.figure(figsize=[7,5])\n",
    "plt.imshow(d, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535fa6b",
   "metadata": {},
   "source": [
    "### Add noise\n",
    "\n",
    "As we can see from above, the data which you loaded in is the noise-free synthetic. This is great for helping us benchmark the results however we are really interested in testing the denoising performance of blind-spot networks there we need to add some noise that we wish to later suppress. Here we use a previously wrote function to add bandlimited noise to the dataset, this way it has some coherency along the time axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5519a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisydata, _ = add_bandlimited_noise(d, sc=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201a417",
   "metadata": {},
   "source": [
    "#### Plot the noisy data to see what it looks like in comparison to the clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[7,5])\n",
    "plt.imshow(noisydata, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5cce5c",
   "metadata": {},
   "source": [
    "### Patch data\n",
    "\n",
    "\n",
    "At the moment we have a single image that we wish to denoise however to train the network we need to give it multiple data examples. Therefore, following common computer vision methodology, we will select random patches from the data for the networks training. \n",
    "\n",
    "Our patch implementation involves first regularly extracting patches from the image and then shuffling the patches such that they are in a random order. Later at the training stage these patches will be split into train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularly extract patches from the noisy data\n",
    "noisy_patches = regular_patching_2D(noisydata, \n",
    "                                    patchsize=[32, 32], # dimensions of extracted patch\n",
    "                                    step=[4,6], # step to be taken in y,x for the extraction procedure\n",
    "                                   )\n",
    "\n",
    "# Randomise patch order\n",
    "shuffler = np.random.permutation(len(noisy_patches))\n",
    "noisy_patches = noisy_patches[shuffler] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a003c1",
   "metadata": {},
   "source": [
    "#### Visualise the training patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6,figsize=[15,7])\n",
    "for i in range(6*3):\n",
    "    axs.ravel()[i].imshow(noisy_patches[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526f914",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020ab55",
   "metadata": {},
   "source": [
    "# Step Two - Blindspot corruption of training data\n",
    "\n",
    "As we already wrote this in Tutorial One then we shall not write it again here. If you wrote it slightly different in Tutorial One then copy-paste it into this notebook.\n",
    "\n",
    "As a reminder:\n",
    "\n",
    ">Now we have made our noisy data into patches such that we have an adequate number to train the network, we now need to pre-process these noisy patches prior to being input into the network. \n",
    ">\n",
    ">Our implementation of the preprocessing involves:\n",
    ">\n",
    ">   - selecting the active pixels \n",
    ">   - selecting the neighbourhood pixel for each active pixel, which it will take the value of\n",
    ">   - replacing each active pixels' value with its neighbourhood pixels' value\n",
    ">   - creating a active pixel 'mask' which shows the location of the active pixels on the patch\n",
    ">    \n",
    ">The first three steps are important for the pre-processing of the noisy patches, whilst the fourth step is required for identifying the locations on which to compute the loss function during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311780a",
   "metadata": {},
   "source": [
    "We are confident this function works as we wrote and checked it in the previous tutorial. \n",
    "\n",
    "#### TO DO: SELECT THE NUMBER OF ACTIVE PIXELS (AS PERCENTAGE) AND NEIGHBOURHOOD RADIUS\n",
    "\n",
    "For the WGN suppression, the percent of active pixels chosen in literature ranges from 0.5 and 2%. However, in this tutorial our noise has some temporal dependency as it is bandlimited. Therefore, Birnie et al., 2021, use a significantly higher percent of active pixels: 25%. This is the equivalent to replacing every fourth pixel value. Randomising the noise but also interupting the consistency of the signal.\n",
    "\n",
    "With respect to the neighbourhood radius, increasing this also helps to add more randomnicity into the corrupted data patches. The value in tutorial one was 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the percent of active pixels per patch\n",
    "perc_active = 25\n",
    "# Choose the neighbourhood_radius to be searched for the neighbouring pixel\n",
    "neighbourhood_radius = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0206eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total number of pixels within a patch\n",
    "total_num_pixels = noisy_patches[0].shape[0]*noisy_patches[0].shape[1]\n",
    "# Compute the number that should be active pixels based on the choosen percentage\n",
    "num_activepixels = int(np.floor((total_num_pixels/100) * perc_active))\n",
    "print(\"Number of active pixels selected: \\n %.2f percent equals %i pixels\"%(perc_active,num_activepixels))\n",
    "\n",
    "# Input the values of your choice into your pre-processing function\n",
    "crpt_patch, mask = multi_active_pixels(noisy_patches[5], \n",
    "                                       num_activepixels=num_activepixels, \n",
    "                                       neighbourhood_radius=neighbourhood_radius, \n",
    "                                      )\n",
    "\n",
    "# Visulise the coverage of active pixels within a patch\n",
    "fig,axs = plot_corruption(noisy_patches[5], crpt_patch, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98452db",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45770a64",
   "metadata": {},
   "source": [
    "# Step three - Set up network\n",
    "\n",
    "As in Tutorial One, we will use a standard UNet architecture. As the architecture is independent to the blind-spot denoising procedure presented, it will be created via functions as opposed to being wrote within the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device for training\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = torch.device(torch.cuda.current_device())\n",
    "    print(f'Device: {device} {torch.cuda.get_device_name(device)}')\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471d6fd",
   "metadata": {},
   "source": [
    "#### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b866458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build UNet from pre-made function\n",
    "network = UNet(input_channels=1, \n",
    "               output_channels=1, \n",
    "               hidden_channels=32,\n",
    "               levels=2).to(device)\n",
    "# Initialise UNet's weights from pre-made function\n",
    "network = network.apply(weights_init) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104ca61",
   "metadata": {},
   "source": [
    "#### TO DO: SELECT THE NETWORKS TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001  # Learning rate\n",
    "criterion = nn.L1Loss()  # Loss function\n",
    "optim = torch.optim.Adam(network.parameters(), lr=lr)  # Optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95ff65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005bca4",
   "metadata": {},
   "source": [
    "# Step four - training\n",
    "\n",
    "Now we have successfully built our network and prepared our data - by patching it to get adequate training samples and creating the input data by selecting and corrupting the active pixels. We are now ready to train the network. Remember, the network training is slightly different to standard image processing tasks in that we will only be computing the loss on the active pixels.\n",
    "\n",
    "As we already wrote the N2V train and validation functions and the training for loop in Tutorial One, we won't rewrite them here. If you wrote it slightly differently than us, please copy-paste your functions into the relevant cells.\n",
    "\n",
    "#### TO DO: DEFINE TRAINING PARAMETERS\n",
    "The longer the network is exposed to the data the better chance it has at learning the signal however it also gets a better chance at learning to recreate the noise. Remember this is in essence, unsupervised learning and the networks target is the original noisy data. Therefore, training for a large number of epochs may be non-optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4494b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of epochs\n",
    "n_epochs = 25\n",
    "\n",
    "# Choose number of training and validation samples\n",
    "n_training = 2048\n",
    "n_test = 512\n",
    "\n",
    "# Choose the batch size for the networks training\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e618ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise arrays to keep track of train and validation metrics\n",
    "train_loss_history = np.zeros(n_epochs)\n",
    "train_accuracy_history = np.zeros(n_epochs)\n",
    "test_loss_history = np.zeros(n_epochs)\n",
    "test_accuracy_history = np.zeros(n_epochs)\n",
    "\n",
    "# Create torch generator with fixed seed for reproducibility, to be used with the data loaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d39caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "for ep in range(n_epochs):  \n",
    "    # RANDOMLY CORRUPT THE NOISY PATCHES\n",
    "    corrupted_patches = np.zeros_like(noisy_patches)\n",
    "    masks = np.zeros_like(corrupted_patches)\n",
    "    for pi in range(len(noisy_patches)):\n",
    "        \n",
    "        # USE ACTIVE PIXEL FUNCTION TO COMPUTE INPUT DATA AND MASKS\n",
    "        corrupted_patches[pi], masks[pi] = multi_active_pixels(noisy_patches[pi], \n",
    "                                                               num_activepixels=int(num_activepixels), \n",
    "                                                               neighbourhood_radius=neighbourhood_radius,)\n",
    "    # MAKE DATA LOADERS - using pre-made function \n",
    "    train_loader, test_loader = make_data_loader(noisy_patches, corrupted_patches, masks, n_training,\n",
    "                                                 n_test, batch_size = batch_size,torch_generator=g)\n",
    "    # TRAIN\n",
    "    train_loss, train_accuracy = n2v_train(network, criterion, optim, train_loader, device,)\n",
    "    # Keeping track of training metrics\n",
    "    train_loss_history[ep], train_accuracy_history[ep] = train_loss, train_accuracy\n",
    "    # EVALUATE (AKA VALIDATION)\n",
    "    test_loss, test_accuracy = n2v_evaluate(network, criterion, optim, test_loader, device,)\n",
    "    # Keeping track of validation metrics\n",
    "    test_loss_history[ep], test_accuracy_history[ep] = test_loss, test_accuracy\n",
    "    # PRINTING TRAINING PROGRESS\n",
    "    print(f'''Epoch {ep}, \n",
    "    Training Loss {train_loss:.4f},     Training Accuracy {train_accuracy:.4f}, \n",
    "    Test Loss {test_loss:.4f},     Test Accuracy {test_accuracy:.4f} ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3643cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trainnig metrics using pre-made function\n",
    "fig,axs = plot_training_metrics(train_accuracy_history,\n",
    "                                test_accuracy_history,\n",
    "                                train_loss_history,\n",
    "                                test_loss_history\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), '/Users/ruslan/Documents/GitHub/Transform2022_SelfSupervisedDenoising/BPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d5a0d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209b9e2",
   "metadata": {},
   "source": [
    "## Step five - Apply trained model\n",
    "\n",
    "The model is now trained and ready for its denoising capabilities to be tested. \n",
    "\n",
    "For the standard network application, the noisy image does not require any data patching nor does it require the active pixel pre-processing required in training. In other words, the noisy image can be fed directly into the network for denoising.\n",
    "\n",
    "#### TO DO: DENOISE NEW NOISY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772cbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('/Users/ruslan/Documents/GitHub/Transform2022_SelfSupervisedDenoising/BPN')\n",
    "\n",
    "# Make a new noisy realisation so it's different from the training set but with roughly same level of noise\n",
    "testdata, _ = add_bandlimited_noise(d, sc=0.1)\n",
    "\n",
    "# Convert dataset in tensor for prediction purposes\n",
    "torch_testdata = torch.from_numpy(np.expand_dims(np.expand_dims(testdata,axis=0),axis=0)).float()\n",
    "\n",
    "# Run test dataset through network\n",
    "network.eval()\n",
    "test_prediction = network(torch_testdata.to(device))\n",
    "\n",
    "# Return to numpy for plotting purposes\n",
    "test_pred = test_prediction.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Use pre-made plotting function to visualise denoising performance\n",
    "fig,axs = plot_synth_results(d, testdata, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amplitude spectra of the base and monitor from 1.5 - 2.5 seconds\n",
    "dt = 4 \n",
    "freq, ampa = fspectra(d.T, dt=dt)\n",
    "_, ampb = fspectra(testdata.T, dt=dt)\n",
    "_, ampc = fspectra(testdata.T-test_pred.T, dt=dt)\n",
    "\n",
    "# Plot the frequency spectra\n",
    "\n",
    "plt.figure(figsize = (11,6))\n",
    "\n",
    "plt.plot(freq, ampa, color='r')\n",
    "plt.plot(freq, ampb, color='b')\n",
    "plt.plot(freq, ampc, color='g')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(labels = ['Clean','Noisy', 'Noise Removed'])\n",
    "plt.title('Amplitude spectra')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a916b63",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183116fc",
   "metadata": {},
   "source": [
    "# PART TWO : APPLYING TO FIELD DATA\n",
    "\n",
    "## STEP ONE: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_data = np.load(\"./data/FieldExample_RandomNoise.npy\")[:696,:300]\n",
    "print(field_data.shape)\n",
    "\n",
    "# Plot to see the noise free data\n",
    "plt.imshow(field_data, cmap=cmap, vmin=vmin, vmax=vmax, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f13667",
   "metadata": {},
   "source": [
    "#### Patch the data and visualise\n",
    "\n",
    "As with all our previous examples, this is only a 2D seismic section therefore we need to patch it to generate adequate training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularly extract patches from the noisy data\n",
    "noisy_patches = regular_patching_2D(field_data, \n",
    "                                    patchsize=[128, 128], # dimensions of extracted patch\n",
    "                                    step=[4,6], # step to be taken in y,x for the extraction procedure\n",
    "                                   )\n",
    "\n",
    "# Randomise patch order\n",
    "shuffler = np.random.permutation(len(noisy_patches))\n",
    "noisy_patches = noisy_patches[shuffler] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552409c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6,figsize=[15,7])\n",
    "for i in range(6*3):\n",
    "    axs.ravel()[i].imshow(noisy_patches[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82358ff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a72719",
   "metadata": {},
   "source": [
    "## STEP TWO: Blindspot corruption of training data\n",
    "\n",
    "#### TO DO: SELECT THE NUMBER OF ACTIVE PIXELS (AS PERCENTAGE) AND NEIGHBOURHOOD RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the percent of active pixels per patch\n",
    "perc_active = 33\n",
    "# Choose the neighbourhood_radius to be searched for the neighbouring pixel\n",
    "neighbourhood_radius = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad831ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total number of pixels within a patch\n",
    "total_num_pixels = noisy_patches[0].shape[0]*noisy_patches[0].shape[1]\n",
    "# Compute the number that should be active pixels based on the choosen percentage\n",
    "num_activepixels = int(np.floor((total_num_pixels/100) * perc_active))\n",
    "print(\"Number of active pixels selected: \\n %.2f percent equals %i pixels\"%(perc_active,num_activepixels))\n",
    "\n",
    "# Input the values of your choice into your pre-processing function\n",
    "crpt_patch, mask = multi_active_pixels(noisy_patches[5], \n",
    "                                       num_activepixels=num_activepixels, \n",
    "                                       neighbourhood_radius=neighbourhood_radius, \n",
    "                                      )\n",
    "\n",
    "# Visulise the coverage of active pixels within a patch\n",
    "fig,axs = plot_corruption(noisy_patches[5], crpt_patch, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d608b5c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224b0fa",
   "metadata": {},
   "source": [
    "## STEP THREE: Set up network\n",
    "\n",
    "Use the same network architecture as earlier examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b96dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build UNet from pre-made function\n",
    "network = UNet(input_channels=1, \n",
    "               output_channels=1, \n",
    "               hidden_channels=32,\n",
    "               levels=2).to(device)\n",
    "# Initialise UNet's weights from pre-made function\n",
    "network = network.apply(weights_init) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0e4c3",
   "metadata": {},
   "source": [
    "#### TO DO: SELECT THE NETWORKS TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a702aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001  # Learning rate\n",
    "criterion = nn.L1Loss()  # Loss function\n",
    "optim = torch.optim.Adam(network.parameters(), lr=lr)  # Optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b3416",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6868e07",
   "metadata": {},
   "source": [
    "# STEP FOUR: Training\n",
    "\n",
    "As we have the functions already above then we only need to repeat the defining of the training parameters and the training for loop.\n",
    "\n",
    "#### TO DO: DEFINE TRAINING PARAMETERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of epochs\n",
    "n_epochs =   \n",
    "\n",
    "# Choose number of training and validation samples\n",
    "n_training = \n",
    "n_test = \n",
    "\n",
    "# Choose the batch size for the networks training\n",
    "batch_size = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67214ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise arrays to keep track of train and validation metrics\n",
    "train_loss_history = np.zeros(n_epochs)\n",
    "train_accuracy_history = np.zeros(n_epochs)\n",
    "test_loss_history = np.zeros(n_epochs)\n",
    "test_accuracy_history = np.zeros(n_epochs)\n",
    "\n",
    "# Create torch generator with fixed seed for reproducibility, to be used with the data loaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb247be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "for ep in range(n_epochs):  \n",
    "        \n",
    "    # RANDOMLY CORRUPT THE NOISY PATCHES\n",
    "    corrupted_patches = np.zeros_like(noisy_patches)\n",
    "    masks = np.zeros_like(corrupted_patches)\n",
    "    for pi in range(len(noisy_patches)):        \n",
    "        corrupted_patches[pi], masks[pi] = multi_active_pixels(noisy_patches[pi], \n",
    "                                                               num_activepixels=int(num_activepixels), \n",
    "                                                               neighbourhood_radius=neighbourhood_radius, \n",
    "                                                              )\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # MAKE DATA LOADERS - using pre-made function \n",
    "    train_loader, test_loader = make_data_loader(noisy_patches, \n",
    "                                                 corrupted_patches, \n",
    "                                                 masks, \n",
    "                                                 n_training,\n",
    "                                                 n_test,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 torch_generator=g\n",
    "                                                )\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # TRAIN\n",
    "    train_loss, train_accuracy = n2v_train(network, \n",
    "                                           criterion, \n",
    "                                           optim, \n",
    "                                           train_loader, \n",
    "                                           device,)\n",
    "    # Keeping track of training metrics\n",
    "    train_loss_history[ep], train_accuracy_history[ep] = train_loss, train_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # EVALUATE (AKA VALIDATION)\n",
    "    test_loss, test_accuracy = n2v_evaluate(network, \n",
    "                                            criterion,\n",
    "                                            optim,\n",
    "                                            test_loader, \n",
    "                                            device,)\n",
    "    # Keeping track of validation metrics\n",
    "    test_loss_history[ep], test_accuracy_history[ep] = test_loss, test_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # PRINTING TRAINING PROGRESS\n",
    "    print(f'''Epoch {ep}, \n",
    "    Training Loss {train_loss:.4f},     Training Accuracy {train_accuracy:.4f}, \n",
    "    Test Loss {test_loss:.4f},     Test Accuracy {test_accuracy:.4f} ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336da8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trainnig metrics using pre-made function\n",
    "fig,axs = plot_training_metrics(train_accuracy_history,\n",
    "                                test_accuracy_history,\n",
    "                                train_loss_history,\n",
    "                                test_loss_history\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2077cd1",
   "metadata": {},
   "source": [
    "## Step five - Apply trained model\n",
    "\n",
    "The model is now trained and ready for its denoising capabilities to be tested. \n",
    "\n",
    "For the standard network application, the noisy image does not require any data patching nor does it require the active pixel pre-processing required in training. In other words, the noisy image can be fed directly into the network for denoising.\n",
    "\n",
    "#### TO DO: APPLY THE NETWORK TO THE ORIGINAL NOISY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert field dataset to tensor for prediction purposes\n",
    "torch_testdata = torch.from_numpy(np.expand_dims(np.expand_dims(field_data,axis=0),axis=0)).float()\n",
    "\n",
    "# Run test dataset through network\n",
    "network.eval()\n",
    "test_prediction = network(torch_testdata.to(device))\n",
    "\n",
    "# Return to numpy for plotting purposes\n",
    "test_pred = test_prediction.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Use pre-made plotting function to visualise denoising performance\n",
    "fig,axs = plot_field_results(field_data, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec1019",
   "metadata": {},
   "source": [
    "## Let's load a new dataset with SEGYIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b2f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segyio\n",
    "import sklearn.preprocessing as sk\n",
    "plt.rcParams[\"figure.figsize\"] = (20,30)\n",
    "# Define the path to seismic file\n",
    "filename = '/Users/ruslan/Downloads/Ichthys 3D seismic for fault competition.segy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open(filename) as segyfile:\n",
    "    seis_data = segyio.tools.cube(filename)\n",
    "    xlines = segyfile.xlines\n",
    "    ilines = segyfile.ilines\n",
    "    samples = segyfile.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a282502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to see the noise free data\n",
    "seis_image = sk.normalize(seis_data[100,:300,:300].T, norm='max')\n",
    "plt.imshow(seis_image, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularly extract patches from the noisy data\n",
    "noisy_patches = regular_patching_2D(seis_image, \n",
    "                                    patchsize=[32, 32], # dimensions of extracted patch\n",
    "                                    step=[4,6], # step to be taken in y,x for the extraction procedure\n",
    "                                   )\n",
    "\n",
    "# Randomise patch order\n",
    "shuffler = np.random.permutation(len(noisy_patches))\n",
    "noisy_patches = noisy_patches[shuffler] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6,figsize=[15,7])\n",
    "for i in range(6*3):\n",
    "    axs.ravel()[i].imshow(noisy_patches[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert field dataset to tensor for prediction purposes\n",
    "torch_testdata = torch.from_numpy(np.expand_dims(np.expand_dims(seis_image,axis=0),axis=0)).float()\n",
    "\n",
    "# Run test dataset through network\n",
    "network.eval()\n",
    "test_prediction = network(torch_testdata[:, :, :1000, :1000].to(device))\n",
    "\n",
    "# Return to numpy for plotting purposes\n",
    "test_pred = test_prediction.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Use pre-made plotting function to visualise denoising performance\n",
    "fig,axs = plot_field_results(seis_image, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516f74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee248c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, ampb = fspectra(field_data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisydata.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea325b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(noisydata.T[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5568691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the amplitude spectra of the base and monitor from 1.5 - 2.5 seconds\n",
    "dt = 4 \n",
    "freq, ampb = fspectra(d.T, dt=dt)\n",
    "_, ampm = fspectra(test_pred.T, dt=dt)\n",
    "\n",
    "# Plot the frequency spectra\n",
    "\n",
    "plt.figure(figsize = (11,6))\n",
    "\n",
    "plt.plot(freq, ampb, color='r')\n",
    "plt.plot(freq, ampm, color='b')\n",
    "\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(labels = ['Base','Monitor'])\n",
    "plt.title('Amplitude spectra')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102d9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
