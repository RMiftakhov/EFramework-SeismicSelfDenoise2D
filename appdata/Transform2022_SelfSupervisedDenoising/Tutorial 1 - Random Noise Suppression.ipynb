{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5960fec8",
   "metadata": {},
   "source": [
    "# SELF-SUPERVISED DENOISING: PART ONE\n",
    "### Authors: Claire Birnie and Sixiu Liu, KAUST\n",
    "\n",
    "Author websites: \n",
    "- https://cebirnie92.github.io/ \n",
    "- https://swagroup.kaust.edu.sa/people/detail/sixiu-liu-(%E5%88%98%E6%80%9D%E7%A7%80))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdf19b",
   "metadata": {},
   "source": [
    "## Tutorial Overview\n",
    "\n",
    "On completion of this tutorial you will have learnt how to write your own blind-spot denoising procedure that is trained in a self-supervised manner, i.e., the training data is the same as the inference data with no labels required!\n",
    "\n",
    "## Methodology Recap\n",
    "We will implement the Noise2Void methodology of blind-spot networks for denoising. This involves performing a pre-processing step which identifies the 'active' pixels and then replaces their original noisy value with that of a neighbouring pixel. This processed data becomes the input to the neural network with the original noisy image being the network's target. However, unlike in most NN applications, the loss is not computed across the full predicted image, but only at the active pixel locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904afec8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe651d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary basic packages\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Import necessary torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "# Import our pre-made functions which will keep the notebook concise\n",
    "# These functions are independent to the blindspot application however important for the data handling and \n",
    "# network creation/initialisation\n",
    "from unet import UNet\n",
    "from tutorial_utils import regular_patching_2D, add_whitegaussian_noise, weights_init, set_seed, make_data_loader, plot_corruption, plot_training_metrics, plot_synth_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d875ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some general plotting parameters so we don't need to keep adding them later on\n",
    "cmap='RdBu'\n",
    "vmin = -0.25\n",
    "vmax = 0.25\n",
    "\n",
    "# For reproducibility purposes we set random, numpy and torch seeds\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965b28e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af110b58",
   "metadata": {},
   "source": [
    "# Step One - Data loading\n",
    "\n",
    "In this example we are going to use a post-stack seismic section generated from the Hess VTI model. The post-stack section is available in the public data folder: https://exrcsdrive.kaust.edu.sa/exrcsdrive/index.php/s/vjjry6BZ3n3Ewei\n",
    "\n",
    "with password: `kaust`\n",
    "\n",
    "If the folder is no longer public, this is likely due to expired rights. Please email: cebirnie[at]kaust.edu.sa to request access. \n",
    "\n",
    "In this instance I have downloaded the file and added to a folder in this repository title 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f35f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load(\"./data/Hess_PostStackSection.npy\")\n",
    "\n",
    "# Check data dimensions\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b1dde",
   "metadata": {},
   "source": [
    "#### Plot the data to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[7,5])\n",
    "plt.imshow(d, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f535fa6b",
   "metadata": {},
   "source": [
    "### Add noise\n",
    "\n",
    "As we can see from above, the data which you loaded in is the noise-free synthetic. This is great for helping us benchmark the results however we are really interested in testing the denoising performance of blind-spot networks there we need to add some noise that we wish to later suppress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5519a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisydata, _ = add_whitegaussian_noise(d, sc=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2a0ecfd",
   "metadata": {},
   "source": [
    "#### Plot the noisy data to see what it looks like in comparison to the clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[7,5])\n",
    "#TO DO: PLOT NOISY DATA\n",
    "plt.imshow(noisydata, cmap=cmap, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5cce5c",
   "metadata": {},
   "source": [
    "### Patch data\n",
    "\n",
    "At the moment we have a single image that we wish to denoise however to train the network we need to give it multiple data examples. Therefore, following common computer vision methodology, we will select random patches from the data for the networks training. \n",
    "\n",
    "Our patch implementation involves first regularly extracting patches from the image and then shuffling the patches such that they are in a random order. Later at the training stage these patches will be split into train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularly extract patches from the noisy data\n",
    "noisy_patches = regular_patching_2D(noisydata, \n",
    "                                    patchsize=[32, 32], # dimensions of extracted patch\n",
    "                                    step=[4,6], # step to be taken in y,x for the extraction procedure\n",
    "                                   )\n",
    "\n",
    "# Randomise patch order\n",
    "shuffler = np.random.permutation(len(noisy_patches))\n",
    "noisy_patches = noisy_patches[shuffler] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7efd34ac",
   "metadata": {},
   "source": [
    "#### Visualise the training patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,6,figsize=[15,7])\n",
    "for i in range(6*3):\n",
    "    axs.ravel()[i].imshow(noisy_patches[i], cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526f914",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020ab55",
   "metadata": {},
   "source": [
    "# Step Two - Blindspot corruption of training data\n",
    "\n",
    "Now we have made our noisy data into patches such that we have an adequate number to train the network, we now need to pre-process these noisy patches prior to being input into the network. \n",
    "\n",
    "Our implementation of the preprocessing involves:\n",
    "    - selecting the active pixels \n",
    "    - selecting the neighbourhood pixel for each active pixel, which it will take the value of\n",
    "    - replacing each active pixels' value with its neighbourhood pixels' value\n",
    "    - creating a active pixel 'mask' which shows the location of the active pixels on the patch\n",
    "    \n",
    "The first three steps are important for the pre-processing of the noisy patches, whilst the fourth step is required for identifying the locations on which to compute the loss function during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab1c5a",
   "metadata": {},
   "source": [
    "#### To do: Create a function that randomly selects and corrupts pixels following N2V methodology"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9b47d8f",
   "metadata": {},
   "source": [
    "def multi_active_pixels(patch, \n",
    "                        num_activepixels, \n",
    "                        neighbourhood_radius=5,\n",
    "                       ):\n",
    "    \"\"\" Function to identify multiple active pixels and replace with values from neighbouring pixels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patch : numpy 2D array\n",
    "        Noisy patch of data to be processed\n",
    "    num_activepixels : int\n",
    "        Number of active pixels to be selected within the patch\n",
    "    neighbourhood_radius : int\n",
    "        Radius over which to select neighbouring pixels for active pixel value replacement\n",
    "    Returns\n",
    "    -------\n",
    "        cp_ptch : numpy 2D array\n",
    "            Processed patch \n",
    "        mask : numpy 2D array\n",
    "            Mask showing location of active pixels within the patch \n",
    "    \"\"\"\n",
    "\n",
    "    n_rad = neighbourhood_radius  # descriptive variable name was a little long\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP ONE: SELECT ACTIVE PIXEL LOCATIONS\n",
    "    \n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP TWO: SELECT NEIGHBOURING PIXEL LOCATIONS\n",
    "    \n",
    "    # PART 1: Compute Shift\n",
    "    # For each active pixel compute shift for finding neighbouring pixel and find pixel\n",
    "    \n",
    "    \n",
    "    # OPTIONAL: don't allow replacement with itself\n",
    "    \n",
    "\n",
    "    # PART 2: Find x and y locations of neighbours for the replacement\n",
    "    \n",
    "    \n",
    "    # Ensure neighbouring pixels within patch window\n",
    "    \n",
    "    \n",
    "    # Get x,y of neighbouring pixels\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP THREE: REPLACE ACTIVE PIXEL VALUES BY NEIGHBOURS\n",
    "    \n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP FOUR: MAKE ACTIVE PIXEL MASK\n",
    "    # Make mask \n",
    "    \n",
    "    \n",
    "    return cp_patch, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_active_pixels(patch, \n",
    "                        num_activepixels, \n",
    "                        neighbourhood_radius=5,\n",
    "                       ):\n",
    "    \"\"\" Function to identify multiple active pixels and replace with values from neighbouring pixels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    patch : numpy 2D array\n",
    "        Noisy patch of data to be processed\n",
    "    num_activepixels : int\n",
    "        Number of active pixels to be selected within the patch\n",
    "    neighbourhood_radius : int\n",
    "        Radius over which to select neighbouring pixels for active pixel value replacement\n",
    "    Returns\n",
    "    -------\n",
    "        cp_ptch : numpy 2D array\n",
    "            Processed patch \n",
    "        mask : numpy 2D array\n",
    "            Mask showing location of active pixels within the patch \n",
    "    \"\"\"\n",
    "\n",
    "    n_rad = neighbourhood_radius  # descriptive variable name was a little long\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP ONE: SELECT ACTIVE PIXEL LOCATIONS\n",
    "    idx_aps = np.random.randint(0, patch.shape[0], num_activepixels)\n",
    "    idy_aps = np.random.randint(0, patch.shape[1], num_activepixels)\n",
    "    id_aps = (idx_aps, idy_aps)\n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP TWO: SELECT NEIGHBOURING PIXEL LOCATIONS\n",
    "    \n",
    "    # PART 1: Compute Shift\n",
    "    # For each active pixel compute shift for finding neighbouring pixel and find pixel\n",
    "    x_neigh_shft = np.random.randint(-n_rad // 2 + n_rad % 2, n_rad // 2 + n_rad % 2, num_activepixels)\n",
    "    y_neigh_shft = np.random.randint(-n_rad // 2 + n_rad % 2, n_rad // 2 + n_rad % 2, num_activepixels)\n",
    "    \n",
    "    # OPTIONAL: don't allow replacement with itself\n",
    "    for i in range(len(x_neigh_shft)):\n",
    "        if x_neigh_shft[i] == 0 and y_neigh_shft[i] == 0:\n",
    "            # This means its replacing itself with itself...\n",
    "            shft_options = np.trim_zeros(np.arange(-n_rad // 2 + 1, n_rad // 2 + 1))\n",
    "            x_neigh_shft[i] = np.random.choice(shft_options[shft_options != 0], 1)\n",
    "\n",
    "    # PART 2: Find x and y locations of neighbours for the replacement\n",
    "    idx_neigh = idx_aps + x_neigh_shft\n",
    "    idy_neigh = idy_aps + y_neigh_shft    \n",
    "    \n",
    "    # Ensure neighbouring pixels within patch window\n",
    "    idx_neigh = idx_neigh + (idx_neigh < 0) * patch.shape[0] - (idx_neigh >= patch.shape[0]) * patch.shape[0]\n",
    "    idy_neigh = idy_neigh + (idy_neigh < 0) * patch.shape[1] - (idy_neigh >= patch.shape[1]) * patch.shape[1]\n",
    "    # Get x,y of neighbouring pixels\n",
    "    id_neigh = (idx_neigh, idy_neigh)\n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP THREE: REPLACE ACTIVE PIXEL VALUES BY NEIGHBOURS\n",
    "    cp_ptch = patch.copy()\n",
    "    cp_ptch[id_aps] = patch[id_neigh]\n",
    "    \n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # STEP FOUR: MAKE ACTIVE PIXEL MASK\n",
    "    mask = np.ones_like(patch)\n",
    "    mask[id_aps] = 0.\n",
    "\n",
    "    return cp_ptch, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa4038",
   "metadata": {},
   "source": [
    "#### TO DO:  CHECK THE CORRUPTION FUNCTION WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5949a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the values of your choice into your pre-processing function\n",
    "crpt_patch, mask = multi_active_pixels(noisy_patches[6], \n",
    "                                       num_activepixels=%FILL%, \n",
    "                                       neighbourhood_radius=%FILL%, \n",
    "                                      )\n",
    "\n",
    "# Use the pre-made plotting function to visualise the corruption\n",
    "fig,axs = plot_corruption(noisy_patches[6], crpt_patch, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e573e5",
   "metadata": {},
   "source": [
    "#### TO DO: SELECT THE NUMBER OF ACTIVE PIXELS (AS PERCENTAGE)\n",
    "\n",
    "In the original N2V examples the authors use between 0.5 and 2% for the number of active pixels within a patch.\n",
    "\n",
    "In Birnie et al., 2021 where they use this methodology for the suppression of white, Gaussian noise, the authors use 0.2%. However, in their example they have substantially more training patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aaee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the percent of active pixels per patch\n",
    "perc_active = %FILL%\n",
    "\n",
    "# Compute the total number of pixels within a patch\n",
    "total_num_pixels = noisy_patches[0].shape[0]*noisy_patches[0].shape[1]\n",
    "\n",
    "# Compute the number that should be active pixels based on the choosen percentage\n",
    "num_activepixels = int(np.floor((total_num_pixels/100) * perc_active))\n",
    "\n",
    "print(\"Number of active pixels selected: \\n %.2f percent equals %i pixels\"%(perc_active,num_activepixels))\n",
    "\n",
    "\n",
    "# Input the values of your choice into your pre-processing function\n",
    "crpt_patch, mask = multi_active_pixels(noisy_patches[6], \n",
    "                                       num_activepixels=num_activepixels, \n",
    "                                       neighbourhood_radius=5, \n",
    "                                      )\n",
    "\n",
    "# Visulise the coverage of active pixels within a patch\n",
    "fig,axs = plot_corruption(noisy_patches[6], crpt_patch, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98452db",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45770a64",
   "metadata": {},
   "source": [
    "# Step three - Set up network\n",
    "\n",
    "In the N2V application of Krull et al., 2018, the network is not specially tailored to the blindspot task. As such, in theory any network could be used that goes from one input image to another of the same size.\n",
    "\n",
    "In this example, like in Krull et al., 2018 and Birnie et al., 2021's seismic application, we will use a standard UNet architecture. As the architecture is independent to the blind-spot denoising procedure presented, it will be created via functions as opposed to being wrote within the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device for training\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = torch.device(torch.cuda.current_device())\n",
    "    print(f'Device: {device} {torch.cuda.get_device_name(device)}')\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b83172",
   "metadata": {},
   "source": [
    "#### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b866458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build UNet from pre-made function\n",
    "network = UNet(input_channels=1, \n",
    "               output_channels=1, \n",
    "               hidden_channels=32,\n",
    "               levels=2).to(device)\n",
    "# Initialise UNet's weights from pre-made function\n",
    "network = network.apply(weights_init) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1f060cb",
   "metadata": {},
   "source": [
    "#### Select the networks training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4  # Learning rate\n",
    "criterion =  nn.MSELoss() # Loss function\n",
    "optim = torch.optim.Adam(network.parameters(), lr=lr) # Optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95ff65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005bca4",
   "metadata": {},
   "source": [
    "# Step four - Network Training\n",
    "\n",
    "Now we have successfully built our network and prepared our data - by patching it to get adequate training samples and creating the input data by selecting and corrupting the active pixels. We are now ready to train the network.\n",
    "\n",
    "Remember, the network training is slightly different to standard image processing tasks in that we will only be computing the loss on the active pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c98e3",
   "metadata": {},
   "source": [
    "#### TO DO: DEFINE TRAINING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of epochs\n",
    "n_epochs = %FILL%  # most recommend 150-200 for random noise suppression \n",
    "\n",
    "# Choose number of training and validation samples (Take note of total # patches available)\n",
    "n_training = %FILL%\n",
    "n_test = %FILL%\n",
    "\n",
    "# Choose the batch size for the networks training\n",
    "batch_size = %FILL%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e618ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise arrays to keep track of train and validation metrics\n",
    "train_loss_history = np.zeros(n_epochs)\n",
    "train_accuracy_history = np.zeros(n_epochs)\n",
    "test_loss_history = np.zeros(n_epochs)\n",
    "test_accuracy_history = np.zeros(n_epochs)\n",
    "\n",
    "# Create torch generator with fixed seed for reproducibility, to be used with the data loaders\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a3a37",
   "metadata": {},
   "source": [
    "#### TO DO: INCORPORATE LOSS FUNCTION INTO TRAINING PROCEDURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2v_train(model, \n",
    "              criterion, \n",
    "              optimizer, \n",
    "              data_loader, \n",
    "              device):\n",
    "    \"\"\" Blind-spot network training function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch model\n",
    "        Neural network\n",
    "    criterion : torch criterion\n",
    "        Loss function \n",
    "    optimizer : torch optimizer\n",
    "        Network optimiser\n",
    "    data_loader : torch dataloader\n",
    "        Premade data loader with training data batches\n",
    "    device : torch device\n",
    "        Device where training will occur (e.g., CPU or GPU)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        loss : float\n",
    "            Training loss across full dataset (i.e., all batches)\n",
    "        accuracy : float\n",
    "            Training RMSE accuracy across full dataset (i.e., all batches) \n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    accuracy = 0  # initialise accuracy at zero for start of epoch\n",
    "    loss = 0  # initialise loss at zero for start of epoch\n",
    "\n",
    "    for dl in tqdm(data_loader):\n",
    "        # Load batch of data from data loader \n",
    "        X, y, mask = dl[0].to(device), dl[1].to(device), dl[2].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Predict the denoised image based on current network weights\n",
    "        yprob = model(X)\n",
    "\n",
    "        #  ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "        # TO DO: Compute loss function only at masked locations and backpropogate it\n",
    "        # (Hint: only two lines required)\n",
    "        ls =  \n",
    "        \n",
    "        #  ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "        \n",
    "        \n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            yprob = yprob\n",
    "            ypred = (yprob.detach().cpu().numpy()).astype(float)\n",
    "            \n",
    "        # Retain training metrics\n",
    "        loss += ls.item()  \n",
    "        accuracy += np.sqrt(np.mean((y.cpu().numpy().ravel( ) - ypred.ravel() )**2))  \n",
    "        \n",
    "    # Divide cumulative training metrics by number of batches for training\n",
    "    loss /= len(data_loader)  \n",
    "    accuracy /= len(data_loader)  \n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012b96a",
   "metadata": {},
   "source": [
    "#### TO DO: INCORPORATE LOSS FUNCTION INTO VALIDATION PROCEDURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9566266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2v_evaluate(model,\n",
    "                 criterion, \n",
    "                 optimizer, \n",
    "                 data_loader, \n",
    "                 device):\n",
    "    \"\"\" Blind-spot network evaluation function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch model\n",
    "        Neural network\n",
    "    criterion : torch criterion\n",
    "        Loss function \n",
    "    optimizer : torch optimizer\n",
    "        Network optimiser\n",
    "    data_loader : torch dataloader\n",
    "        Premade data loader with training data batches\n",
    "    device : torch device\n",
    "        Device where network computation will occur (e.g., CPU or GPU)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        loss : float\n",
    "            Validation loss across full dataset (i.e., all batches)\n",
    "        accuracy : float\n",
    "            Validation RMSE accuracy across full dataset (i.e., all batches) \n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    accuracy = 0  # initialise accuracy at zero for start of epoch\n",
    "    loss = 0  # initialise loss at zero for start of epoch\n",
    "\n",
    "    for dl in tqdm(data_loader):\n",
    "        \n",
    "        # Load batch of data from data loader \n",
    "        X, y, mask = dl[0].to(device), dl[1].to(device), dl[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        yprob = model(X)\n",
    "\n",
    "        with torch.no_grad():            \n",
    "            #  ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "            # TO DO: Compute loss function only at masked locations \n",
    "            # (Hint: only one line required)\n",
    "            ls =  \n",
    "            \n",
    "            #  ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n",
    "        \n",
    "            ypred = (yprob.detach().cpu().numpy()).astype(float)\n",
    "        \n",
    "        # Retain training metrics\n",
    "        loss += ls.item()  \n",
    "        accuracy += np.sqrt(np.mean((y.cpu().numpy().ravel( ) - ypred.ravel() )**2))  \n",
    "        \n",
    "    # Divide cumulative training metrics by number of batches for training\n",
    "    loss /= len(data_loader)  \n",
    "    accuracy /= len(data_loader)  \n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e718d9",
   "metadata": {},
   "source": [
    "#### TO DO: COMPLETE TRAINING LOOP BY INCORPORATING ABOVE FUNCTIONS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b32bbb",
   "metadata": {},
   "source": [
    "# TRAINING\n",
    "for ep in range(n_epochs):  \n",
    "        \n",
    "    # RANDOMLY CORRUPT THE NOISY PATCHES\n",
    "    corrupted_patches = np.zeros_like(noisy_patches)\n",
    "    masks = np.zeros_like(corrupted_patches)\n",
    "    for pi in range(len(noisy_patches)):\n",
    "        \n",
    "        # TO DO: USE ACTIVE PIXEL FUNCTION TO COMPUTE INPUT DATA AND MASKS\n",
    "        # Hint: One line of code\n",
    "        corrupted_patches[pi], masks[pi] = \n",
    "        \n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # MAKE DATA LOADERS - using pre-made function \n",
    "    train_loader, test_loader = make_data_loader(noisy_patches, \n",
    "                                                 corrupted_patches, \n",
    "                                                 masks, \n",
    "                                                 n_training,\n",
    "                                                 n_test,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 torch_generator=g\n",
    "                                                )\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # TRAIN\n",
    "    # TO DO: Incorporate previously wrote n2v_train function\n",
    "    train_loss, train_accuracy =\n",
    "    \n",
    "    \n",
    "    # Keeping track of training metrics\n",
    "    train_loss_history[ep], train_accuracy_history[ep] = train_loss, train_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # EVALUATE (AKA VALIDATION)\n",
    "    # TO DO: Incorporate previously wrote n2v_evaluate function\n",
    "    test_loss, test_accuracy = \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Keeping track of validation metrics\n",
    "    test_loss_history[ep], test_accuracy_history[ep] = test_loss, test_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # PRINTING TRAINING PROGRESS\n",
    "    print(f'''Epoch {ep}, \n",
    "    Training Loss {train_loss:.4f},     Training Accuracy {train_accuracy:.4f}, \n",
    "    Test Loss {test_loss:.4f},     Test Accuracy {test_accuracy:.4f} ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d39caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "for ep in range(n_epochs):  \n",
    "        \n",
    "    # RANDOMLY CORRUPT THE NOISY PATCHES\n",
    "    corrupted_patches = np.zeros_like(noisy_patches)\n",
    "    masks = np.zeros_like(corrupted_patches)\n",
    "    for pi in range(len(noisy_patches)):\n",
    "        \n",
    "        # TO DO: USE ACTIVE PIXEL FUNCTION TO COMPUTE INPUT DATA AND MASKS\n",
    "        # Hint: One line of code\n",
    "        corrupted_patches[pi], masks[pi] = multi_active_pixels(noisy_patches[pi], \n",
    "                                                               num_activepixels=num_activepixels, \n",
    "                                                               neighbourhood_radius=5, \n",
    "                                                              )\n",
    "        \n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # MAKE DATA LOADERS - using pre-made function \n",
    "    train_loader, test_loader = make_data_loader(noisy_patches, \n",
    "                                                 corrupted_patches, \n",
    "                                                 masks, \n",
    "                                                 n_training,\n",
    "                                                 n_test,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 torch_generator=g\n",
    "                                                )\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # TRAIN\n",
    "    # TO DO: Incorporate previously wrote n2v_train function\n",
    "    train_loss, train_accuracy = n2v_train(network, \n",
    "              criterion, \n",
    "              optim, \n",
    "              train_loader, \n",
    "              device)\n",
    "    \n",
    "    \n",
    "    # Keeping track of training metrics\n",
    "    train_loss_history[ep], train_accuracy_history[ep] = train_loss, train_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # EVALUATE (AKA VALIDATION)\n",
    "    # TO DO: Incorporate previously wrote n2v_evaluate function\n",
    "    test_loss, test_accuracy = n2v_evaluate(network,\n",
    "                 criterion, \n",
    "                 optim, \n",
    "                 test_loader, \n",
    "                 device)\n",
    "    \n",
    "    \n",
    "    # Keeping track of validation metrics\n",
    "    test_loss_history[ep], test_accuracy_history[ep] = test_loss, test_accuracy\n",
    "\n",
    "    # ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \n",
    "    # PRINTING TRAINING PROGRESS\n",
    "    print(f'''Epoch {ep}, \n",
    "    Training Loss {train_loss:.4f},     Training Accuracy {train_accuracy:.4f}, \n",
    "    Test Loss {test_loss:.4f},     Test Accuracy {test_accuracy:.4f} ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3643cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trainnig metrics using pre-made function\n",
    "fig,axs = plot_training_metrics(train_accuracy_history,\n",
    "                                test_accuracy_history,\n",
    "                                train_loss_history,\n",
    "                                test_loss_history\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d5a0d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209b9e2",
   "metadata": {},
   "source": [
    "## Step five - Apply trained model\n",
    "\n",
    "The model is now trained and ready for its denoising capabilities to be tested. \n",
    "\n",
    "For the standard network application, the noisy image does not require any data patching nor does it require the active pixel pre-processing required in training. In other words, the noisy image can be fed directly into the network for denoising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c7bba",
   "metadata": {},
   "source": [
    "#### TO DO: DENOISE NEW NOISY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff53757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new noisy realisation so it's different from the training set but with roughly same level of noise\n",
    "testdata, _ = add_whitegaussian_noise(d, sc=0.1)\n",
    "\n",
    "# Convert dataset in tensor for prediction purposes\n",
    "torch_testdata = torch.from_numpy(np.expand_dims(np.expand_dims(testdata, axis=0), axis=0)).float()\n",
    "\n",
    "# Run test dataset through network\n",
    "network.eval()\n",
    "test_prediction = network(torch_testdata.to(device))\n",
    "\n",
    "# Return to numpy for plotting purposes\n",
    "test_pred = test_prediction.detach().cpu().numpy().squeeze()\n",
    "\n",
    "# Use pre-made plotting function to visualise denoising performance\n",
    "fig,axs = plot_synth_results(d, testdata, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ca5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
